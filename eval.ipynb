{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0b5e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "加载了 5261 条测试序列\n",
      "测试标签文件包含 5261 条记录\n",
      "成功匹配了 5261 条测试序列的标签\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/transformers_modules/checkpoint-6139/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试集评估结果:\n",
      "准确率 (Accuracy): 0.9899\n",
      "精确率 (Precision): 0.9901\n",
      "召回率 (Recall): 0.9899\n",
      "F1分数: 0.9900\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        H1N1       0.98      0.99      0.99      1678\n",
      "        H3N2       1.00      0.99      0.99      3452\n",
      "        H5N1       1.00      0.94      0.97        36\n",
      "        H7N9       0.92      0.97      0.94        34\n",
      "        H9N2       0.90      0.98      0.94        61\n",
      "\n",
      "    accuracy                           0.99      5261\n",
      "   macro avg       0.96      0.98      0.97      5261\n",
      "weighted avg       0.99      0.99      0.99      5261\n",
      "\n",
      "混淆矩阵已保存到 /root/autodl-tmp/Influenza_BERT/new_class_5/checkpoint-6139/confusion_matrix.png\n",
      "详细预测结果已保存到 /root/autodl-tmp/Influenza_BERT/new_class_5/checkpoint-6139/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class VirusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, labels, tokenizer, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        sequence = ''.join(c for c in sequence.upper() if c in ['A', 'T', 'G', 'C', 'N'])\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            sequence,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_test_data(fasta_file, label_file, label_mapping_file):\n",
    "    label_to_idx = {}\n",
    "    idx_to_label = {}\n",
    "    with open(label_mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            idx, label = line.strip().split('\\t')\n",
    "            idx = int(idx)\n",
    "            label_to_idx[label] = idx\n",
    "            idx_to_label[idx] = label\n",
    "    \n",
    "    # 加载序列\n",
    "    sequences = []\n",
    "    seq_ids = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append(str(record.seq))\n",
    "        main_id = record.id.split('|')[0]\n",
    "        seq_ids.append(main_id)\n",
    "    \n",
    "    print(f\"加载了 {len(sequences)} 条测试序列\")\n",
    "    \n",
    "    # 加载标签\n",
    "    labels_df = pd.read_csv(label_file)\n",
    "    print(f\"测试标签文件包含 {len(labels_df)} 条记录\")\n",
    "    id_to_label = dict(zip(labels_df['accession'], labels_df['subtype']))\n",
    "    \n",
    "    # 匹配序列和标签\n",
    "    labels = []\n",
    "    valid_seq_ids = []\n",
    "    valid_sequences = []\n",
    "    \n",
    "    for i, seq_id in enumerate(seq_ids):\n",
    "        if seq_id in id_to_label:\n",
    "            label = id_to_label[seq_id]\n",
    "            if label in label_to_idx: \n",
    "                labels.append(label_to_idx[label])\n",
    "                valid_seq_ids.append(seq_id)\n",
    "                valid_sequences.append(sequences[i])\n",
    "            else:\n",
    "                print(f\"警告: 标签 {label} 在训练集中未出现，跳过序列 {seq_id}\")\n",
    "        else:\n",
    "            print(f\"警告: 序列ID {seq_id} 在标签文件中未找到\")\n",
    "    \n",
    "    print(f\"成功匹配了 {len(labels)} 条测试序列的标签\")\n",
    "    \n",
    "    return valid_sequences, labels, valid_seq_ids, idx_to_label\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, idx_to_label, output_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    labels = [idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8), dpi=800)  # 设置DPI为800\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, 'a_new_class_10_confusion_matrix.png'), dpi=800)  # 保存时也设置DPI为800\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model():\n",
    "    # 设置参数\n",
    "    \n",
    "    model_dir = \"/root/autodl-tmp/Influenza_BERT/new_class_5/checkpoint-6139\"\n",
    "    test_fasta_file = \"/root/autodl-tmp/Influenza_BERT/test_sequences_5.fasta\"\n",
    "    test_label_file = \"/root/autodl-tmp/Influenza_BERT/test_labels_5.csv\"\n",
    "    label_mapping_file = os.path.join(model_dir, \"label_mapping.txt\")\n",
    "    batch_size = 8\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 加载测试数据\n",
    "    test_sequences, test_labels, test_ids, idx_to_label = load_test_data(\n",
    "        test_fasta_file, test_label_file, label_mapping_file\n",
    "    )\n",
    "    \n",
    "    # 加载模型和tokenizer\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建测试数据集和数据加载器\n",
    "    test_dataset = VirusDataset(test_sequences, test_labels, tokenizer)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # 进行预测\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"\\n测试集评估结果:\")\n",
    "    print(f\"准确率 (Accuracy): {accuracy:.4f}\")\n",
    "    print(f\"精确率 (Precision): {precision:.4f}\")\n",
    "    print(f\"召回率 (Recall): {recall:.4f}\")\n",
    "    print(f\"F1分数: {f1:.4f}\")\n",
    "    \n",
    "    # 生成详细的分类报告\n",
    "    target_names = [idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=target_names)\n",
    "    print(\"\\n分类报告:\")\n",
    "    print(class_report)\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    plot_confusion_matrix(all_labels, all_preds, idx_to_label, model_dir)\n",
    "    print(f\"混淆矩阵已保存到 {os.path.join(model_dir, 'confusion_matrix.png')}\")\n",
    "    \n",
    "    # 保存详细的预测结果\n",
    "    results_df = pd.DataFrame({\n",
    "        'sequence_id': test_ids,\n",
    "        'true_label': [idx_to_label[label] for label in all_labels],\n",
    "        'predicted_label': [idx_to_label[pred] for pred in all_preds],\n",
    "        'correct': [pred == label for pred, label in zip(all_preds, all_labels)]\n",
    "    })\n",
    "    \n",
    "    results_file = os.path.join(model_dir, 'test_predictions.csv')\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f\"详细预测结果已保存到 {results_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558eb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4c1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934bca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
